# MNIST 분류 실험 결과

## 기본 모델 성능
- 최종 테스트 정확도: 96.87%
- 훈련 시간: 0분 46초

## 실험 결과
### 실험 1: [학습률 변경에 따른 경향성]
- 변경사항: 기본 모델의 학습률을 변경. 기본값(1e-3)보다 큰 0.01, 0.1, 1 과 기본값보다 작은 1e-4, 1e-5, 1e-6에 대하여 각각 실험.
- 결과: 각 학습률마다 실험을 10회 반복하여 훈련 정확도, 테스트 정확도, 과적합도의 평균과 표준편차를 추출.
  - learning rate = 0.01:
    - 평균 훈련 정확도: 96.01%, 표준편차: 0.10%
    - 평균 테스트 정확도: 95.50%, 표준편차: 0.49%
    - 평균 과적합도: 0.50%, 표준편차: 0.50%
  - learning rate = 0.1:
    - 평균 훈련 정확도: 42.39%, 표준편차: 13.82%
    - 평균 테스트 정확도: 40.47%, 표준편차: 14.90%
    - 평균 과적합도: 1.92%, 표준편차: 5.18%
  - learning rate = 1:
    - 평균 훈련 정확도: 10.52%, 표준편차: 0.44%
    - 평균 테스트 정확도: 10.44%, 표준편차: 0.80%
    - 평균 과적합도: 0.08%, 표준편차: 0.60%
  - learning rate = 1e-4:
    - 평균 훈련 정확도: 91.98%, 표준편차: 0.11%
    - 평균 테스트 정확도: 92.68%, 표준편차: 0.16%
    - 평균 과적합도: -0.70%, 표준편차: 0.12%
  - learning rate = 1e-5:
    - 평균 훈련 정확도: 82.40%, 표준편차: 0.34%
    - 평균 테스트 정확도: 84.92%, 표준편차: 0.32%
    - 평균 과적합도: -2.52%, 표준편차: 0.27%
  - learning rate = 1e-6:
    - 평균 훈련 정확도: 33.87%, 표준편차: 5.35%
    - 평균 테스트 정확도: 40.29%, 표준편차: 4.64%
    - 평균 과적합도: -6.42%, 표준편차: 1.03%
- 분석: 학습률이 기본값과 비슷한 값일수록 정확도가 높은 것을 통해, 기본값으로 지정된 학습률 1e-3이 최적의 학습률임을 믿을 수 있다. learning rate가 커지는 경우, 정확도가 급격히 감소하고 각 학습 결과의 편차가 매우 커지는 것을 확인할 수 있었고 아예 1까지 가면 정확도가 10% 떨어지며 무작위로 고른 것과 별 차이가 없는 결과를 보였다. 반대로 leaning rate가 더 작아지는 경우에는 기본값이 최적의 값을 가지고 있어서 loss는 감소, 정확도는 증가하는 경향성을 보여주었지만 그 변화폭이 기본값보다 너무 적어 기본값인 경우 만큼의 정확도에 도달하지 못했고, 1e-6의 경우엔 아예 초기 정확도에서 거의 벗어나지 못하는 경향을 보였다.

### 실험 2: [은닉층의 크기 조정에 따른 경향성]
- 변경사항: 기본 모델의 은닉층 크기 변경. 기본값(100)보다 큰 200, 400, 600 의 경우와 기본값보다 작은 75, 50, 25에 대하여 각각 실험.
- 결과: 각 은닉층 크기마다 실험을 10회 반복하여 훈련 정확도, 테스트 정확도, 과적합도의 평균과 표준편차를 추출.
  - hidden size = 75
    - 평균 훈련 정확도: 96.54%, 표준편차: 0.09%
    - 평균 테스트 정확도: 96.63%, 표준편차: 0.15%
    - 평균 과적합도: -0.09%, 표준편차: 0.13%
  - hidden size = 50
    - 평균 훈련 정확도: 95.98%, 표준편차: 0.17%
    - 평균 테스트 정확도: 96.20%, 표준편차: 0.13%
    - 평균 과적합도: -0.23%, 표준편차: 0.18%
  - hidden size = 25
    - 평균 훈련 정확도: 94.41%, 표준편차: 0.22%
    - 평균 테스트 정확도: 94.56%, 표준편차: 0.30%
    - 평균 과적합도: -0.15%, 표준편차: 0.16%
  - hidden size = 200
    - 평균 훈련 정확도: 97.62%, 표준편차: 0.05%
    - 평균 테스트 정확도: 97.32%, 표준편차: 0.13%
    - 평균 과적합도: 0.31%, 표준편차: 0.10%
  - hidden size = 400
    - 평균 훈련 정확도: 98.09%, 표준편차: 0.02%
    - 평균 테스트 정확도: 97.58%, 표준편차: 0.11%
    - 평균 과적합도: 0.50%, 표준편차: 0.11%
  - hidden size = 600
    - 평균 훈련 정확도: 98.25%, 표준편차: 0.02%
    - 평균 테스트 정확도: 97.72%, 표준편차: 0.22%
    - 평균 과적합도: 0.53%, 표준편차: 0.22%
- 분석: 전반적으로 은닉층의 크기가 증가할수록 정확도가 증가하는 경향을 보였다. 이는 28x28의 데이터에서 더 다양한 패턴을 분석하기에 더 세밀한 구분이 가능한 것으로 생각된다. 대부분 기본 모델과 크게 다르지 않은 정확도를 보여주었으나 은닉층 크기가 25까지 작아졌을 때 정확도가 비교적 크게 하락했다. 실제 모델은 실행시간이나 메모리 한계도 고려해야하므로 정확도가 크게 떨어지지 않는 선까지 은닉층을 줄여보는 실험도 할 수 있을 것 같다.

### 실험 3: [다른 활성화 함수의 적용]
- 변경사항: 기본 모델의 활성화 함수(ReLU)를 변경. 다른 활성화 함수인 Tanh와 Sigmoid로 변경한 경우에 대하여 각각 실험.
- 결과: 각 활성화 함수를 적용한 경우마다 실험을 10회 반복하여 훈련 정확도, 테스트 정확도, 과적합도의 평균과 표준편차를 추출.
  - Tanh
    - 평균 훈련 정확도: 96.65%, 표준편차: 0.07%
    - 평균 테스트 정확도: 96.50%, 표준편차: 0.17%
    - 평균 과적합도: 0.15%, 표준편차: 0.13%
  - Sigmoid
    - 평균 훈련 정확도: 95.08%, 표준편차: 0.05%
    - 평균 테스트 정확도: 95.22%, 표준편차: 0.12%
    - 평균 과적합도: -0.14%, 표준편차: 0.08%
- 분석: 다른 실험들만큼 정확도에 큰 차이를 보이지는 않았지만 전반적으로 기본값인 ReLU보다 정확도 면에서 떨어지는 경향을 보였다. 이번에는 실험하지 않았지만 모델의 층을 늘리는 경우,sigmoid나 tanh는 기울기 소실 문제가 생길 수 있기 때문에 기본값인 ReLU와 더 큰 차이가 생기지 않을까 생각한다.

## 결론 및 인사이트
- 관찰된 패턴과 이에 따른 가장 효과적인 개선 방법: 학습률은 기본값과 차이가 많이 나는 값일수록 정확도의 하락을 보였으므로 기본값인 1e-3을 그대로 사용하는 것이 좋다. 중간 은닉층은 층이 늘어나지 않고 크기만 조절할 수 있는 경우, 크기가 클 수록 정확도의 개선이 있다. 반대로 크기가 작으면 정확도가 내려가지만 기본값의 절반까지는 그 하락폭이 크지 않으므로 연산으로 인한 실행시간을 줄이고자 한다면 이것 또한 방법이 될 수 있다.
- 추가 개선 아이디어: 학습률이 기본값보다 낮아진 경우 기본값보다는 느리더라도 정확도가 상승하는 경향을 보인다. 추가적인 에포크를 사용하면 느리더라도 세밀한 경사 하강을 통해 학습률이 높을 때보다 조금 더 나은 결과를 얻을 가능성이 있다. 다만 에포크를 늘리는 경우 훈련 데이터에 대한 과적합이 발생할 수 있기 때문에 추가적으로 dropout을 사용하는 실험도 해보고 싶다. 이번에는 모델의 층을 늘리는 실험을 하지 않았지만 은닉층들의 크기를 위의 실험하였던 크기들을 조합하여 실험해보고 싶고 활성화 함수도 한 가지가 아닌 조합하여 사용해보는 등의 실험도 해보고 싶다. 마지막으로 결론적인 수치뿐만 아니라 중간 결과까지 수집하여 경향성을 시각적으로 확인할 수 있도록 개선해보고 싶다.