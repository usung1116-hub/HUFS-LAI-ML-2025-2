# MNIST 분류 실험 결과

## 기본 모델 성능
- 최종 테스트 정확도: 96.86%
- 훈련 시간: 45초

## 실험 결과
### 실험 1: [하이퍼파라미터 튜닝]
- 변경사항: 나머지 설정은 기본 모델과 동일하게 둔 뒤, 학습률을 1e-5부터 10배씩 늘려가며 총 5번 실험
- 결과: 각각의 학습률에 따른 최종 테스트 정확도는 다음과 같았다.

1e-5: 85.52%

1e-4: 92.72%

(기존) 1e-3: 96.86%

1e-2: 95.24%

1e-1: 19.59%

- 분석: 학습률을 높이니 어느정도 학습이 잘 되는 모습을 보이다가, 특정 수준을 넘으니 정확도가 뚝 떨어지는 현상이 관측되었다. 학습률이 너무 높아 손실 함수의 기울기 계산을 하다 오버슈팅 현상이 일어난 것으로 해석된다. 실제로 체감해보니 더 심각해보인다. 처음엔 오류인 줄 알았다.

### 실험 2: [dropout 추가하기]
- 변경사항: 나머지 설정은 기본 모델과 동일하게 둔 뒤, 드롭아웃을 추가하여 실험 (dropout_rate = 0.5, 0.3)
- 결과:

드롭아웃 미적용 시 최종 훈련/테스트 정확도: 96.87% / 96.86%

드롭아웃 적용 시(0.5) 최종 훈련/테스트 정확도: 92.97% / 95.90%

드롭아웃 적용 시(0.3) 최종 훈련/테스트 정확도: 95.09% / 96.69%

- 분석: 드롭아웃 미적용 시에는 최종 훈련 정확도가 테스트 정확도보다 살짝 높은 것을 확인할 수 있었으나, 드롭아웃 적용 시에는 테스트 정확도가 훨씬 높은 것을 확인할 수 있었다. 그러나 최종 정확도는 드롭아웃 적용 시에 미적용 시보다 떨어졌다. 이는 최종적으로 다음과 같이 정리할 수 있다. 드롭아웃은 모델이 훈련 데이터, 즉 특정 특징에 의존하는 경향성을 줄여주지만, 드롭아웃의 비율이 높으면 전체 학습을 저해할 수 있다.

## 결론 및 인사이트
- 가장 효과적인 개선 방법: 기본 모델 세팅 상태에서 주어진 mnist 데이터를 기준으로 학습률은 1e-3이 제일 적절하며, 드롭아웃은 적용하지 않는 것이 최선이다.
- 관찰된 패턴: 학습률은 특정 구간에서부터 모델의 성능을 눈에 띄게 저하시키며, 드롭아웃은 훈련 정확도를 테스트 정확도보다 낮게 유지시킨다.
- 추가 개선 아이디어: 드롭아웃은 약간의 trade-off가 있지만 새로운 데이터에 잘 적응하는 모델을 희망한다면 개선을 위해 고려해볼만한 수단으로 볼 수 있다.

## Credit
- 드롭아웃 적용 방법을 몰라 perplexity의 도움을 받아 구현했다.