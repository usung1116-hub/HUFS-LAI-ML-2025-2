{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "202400190"
      ],
      "metadata": {
        "id": "146YkTamJAUk"
      },
      "id": "146YkTamJAUk"
    },
    {
      "cell_type": "markdown",
      "id": "8c96a48f",
      "metadata": {
        "id": "8c96a48f"
      },
      "source": [
        "# MNIST ì†ê¸€ì”¨ ìˆ«ì ë¶„ë¥˜ íŠœí† ë¦¬ì–¼\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” PyTorchë¥¼ ì‚¬ìš©í•˜ì—¬ MNIST ë°ì´í„°ì…‹ì˜ ì†ê¸€ì”¨ ìˆ«ìë¥¼ ë¶„ë¥˜í•˜ëŠ” ê°„ë‹¨í•œ Multi-Layer Perceptron (MLP) ëª¨ë¸ì„ êµ¬í˜„í•©ë‹ˆë‹¤.\n",
        "\n",
        "## í•™ìŠµ ëª©í‘œ\n",
        "1. PyTorchë¥¼ ì´ìš©í•œ ê¸°ë³¸ì ì¸ ì‹ ê²½ë§ êµ¬í˜„\n",
        "2. ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ ê³¼ì • ì´í•´\n",
        "3. ëª¨ë¸ í›ˆë ¨ ë° í‰ê°€ ê³¼ì • ì²´í—˜\n",
        "4. ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™” ë° ë¶„ì„\n",
        "\n",
        "## ë°ì´í„°ì…‹ ì •ë³´\n",
        "- **MNIST**: 28x28 í”½ì…€ì˜ í‘ë°± ì†ê¸€ì”¨ ìˆ«ì ì´ë¯¸ì§€ (0-9)\n",
        "- **í›ˆë ¨ ë°ì´í„°**: 60,000ê°œ\n",
        "- **í…ŒìŠ¤íŠ¸ ë°ì´í„°**: 10,000ê°œ"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4uzj97p1jfe",
      "metadata": {
        "id": "4uzj97p1jfe"
      },
      "source": [
        "## 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
        "\n",
        "ë¨¼ì € í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ ì„í¬íŠ¸í•©ë‹ˆë‹¤:\n",
        "\n",
        "- **torch**: PyTorchì˜ í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
        "- **torch.nn**: ì‹ ê²½ë§ ë ˆì´ì–´ì™€ ì†ì‹¤í•¨ìˆ˜\n",
        "- **torch.optim**: ìµœì í™” ì•Œê³ ë¦¬ì¦˜ (Adam, SGD ë“±)\n",
        "- **torchvision.transforms**: ì´ë¯¸ì§€ ì „ì²˜ë¦¬\n",
        "- **datasets**: HuggingFace ë°ì´í„°ì…‹ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
        "- **matplotlib**: ì‹œê°í™”\n",
        "- **numpy**: ìˆ˜ì¹˜ ê³„ì‚°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3z7x9hct66v",
      "metadata": {
        "id": "3z7x9hct66v"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from datasets import load_dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"Using CPU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ijq7kclsqrq",
      "metadata": {
        "id": "ijq7kclsqrq"
      },
      "source": [
        "## 2. MLP (Multi-Layer Perceptron) ëª¨ë¸ ì •ì˜\n",
        "\n",
        "ê°„ë‹¨í•œ 3ì¸µ ì‹ ê²½ë§ì„ êµ¬í˜„í•©ë‹ˆë‹¤:\n",
        "\n",
        "1. **ì…ë ¥ì¸µ**: 784ê°œ ë‰´ëŸ° (28Ã—28 í”½ì…€ì„ 1ì°¨ì›ìœ¼ë¡œ í¼ì¹¨)\n",
        "2. **ì€ë‹‰ì¸µ**: 100ê°œ ë‰´ëŸ° + ReLU í™œì„±í™” í•¨ìˆ˜\n",
        "3. **ì¶œë ¥ì¸µ**: 10ê°œ ë‰´ëŸ° (0-9 í´ë˜ìŠ¤)\n",
        "\n",
        "### ì£¼ìš” ê°œë…:\n",
        "- **nn.Linear**: Fully Connected Layer (í˜¹ì€ Dense Layer)\n",
        "- **nn.ReLU**: ReLU í™œì„±í™” í•¨ìˆ˜ (ìŒìˆ˜ëŠ” 0, ì–‘ìˆ˜ëŠ” ê·¸ëŒ€ë¡œ)\n",
        "- **nn.Sequential**: ë ˆì´ì–´ë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ì—°ê²°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "grc170711o7",
      "metadata": {
        "id": "grc170711o7"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size=784, hidden_size=100, num_classes=10):\n",
        "        super(MLP, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(input_size, hidden_size),  # 784 -> 100\n",
        "            nn.ReLU(),                          # í™œì„±í™” í•¨ìˆ˜\n",
        "            nn.Linear(hidden_size, num_classes) # 100 -> 10\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        ìˆœì „íŒŒ í•¨ìˆ˜ // forward propagation\n",
        "        x: ì…ë ¥ í…ì„œ (batch_size, 784)\n",
        "        return: ì¶œë ¥ í…ì„œ (batch_size, 10)\n",
        "        \"\"\"\n",
        "        return self.layers(x)\n",
        "\n",
        "# ëª¨ë¸ ìƒì„± ë° êµ¬ì¡° í™•ì¸\n",
        "model = MLP()\n",
        "print(\"ëª¨ë¸ êµ¬ì¡°:\")\n",
        "print(model)\n",
        "\n",
        "# íŒŒë¼ë¯¸í„° ê°œìˆ˜ ê³„ì‚°\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"\\nì´ íŒŒë¼ë¯¸í„° ìˆ˜: {total_params:,}\")\n",
        "print(f\"í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° ìˆ˜: {trainable_params:,}\")\n",
        "\n",
        "# ê° ë ˆì´ì–´ë³„ íŒŒë¼ë¯¸í„° ìˆ˜ í™•ì¸\n",
        "print(\"\\në ˆì´ì–´ë³„ íŒŒë¼ë¯¸í„°:\")\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"{name}: {param.shape} ({param.numel():,} ê°œ)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ut4tocwnhc",
      "metadata": {
        "id": "ut4tocwnhc"
      },
      "source": [
        "## 3. ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬\n",
        "\n",
        "### 3.1 í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •\n",
        "\n",
        "ë¨¼ì € í•™ìŠµì— ì‚¬ìš©í•  í•˜ì´í¼íŒŒë¼ë¯¸í„°ë“¤ì„ ì •ì˜í•©ë‹ˆë‹¤:\n",
        "\n",
        "- **batch_size**: í•œ ë²ˆì— ì²˜ë¦¬í•  ë°ì´í„°ì˜ ê°œìˆ˜\n",
        "- **learning_rate**: í•™ìŠµë¥  (ë„ˆë¬´ í¬ë©´ ë°œì‚°, ë„ˆë¬´ ì‘ìœ¼ë©´ í•™ìŠµì´ ëŠë¦¼)\n",
        "- **epochs**: ì „ì²´ ë°ì´í„°ì…‹ì„ ëª‡ ë²ˆ ë°˜ë³µí• ì§€"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "so573tx44dm",
      "metadata": {
        "id": "so573tx44dm"
      },
      "outputs": [],
      "source": [
        "# í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •\n",
        "batch_size = 128        # ë°°ì¹˜ í¬ê¸°\n",
        "test_batch_size = 1000  # í…ŒìŠ¤íŠ¸ ë°°ì¹˜ í¬ê¸° (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„ ìœ„í•´ í¬ê²Œ ì„¤ì •)\n",
        "learning_rate = 1e-3    # í•™ìŠµë¥  (0.001)\n",
        "nb_epochs = 3           # ì—í¬í¬ ìˆ˜\n",
        "\n",
        "print(\"=== í•˜ì´í¼íŒŒë¼ë¯¸í„° ===\")\n",
        "print(f\"ë°°ì¹˜ í¬ê¸°: {batch_size}\")\n",
        "print(f\"í…ŒìŠ¤íŠ¸ ë°°ì¹˜ í¬ê¸°: {test_batch_size}\")\n",
        "print(f\"í•™ìŠµë¥ : {learning_rate}\")\n",
        "print(f\"ì—í¬í¬ ìˆ˜: {nb_epochs}\")\n",
        "\n",
        "# ë””ë°”ì´ìŠ¤ ì„¤ì • (GPUê°€ ìˆìœ¼ë©´ GPU ì‚¬ìš©)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"\\nì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}\")\n",
        "if device.type == \"cuda\":\n",
        "    print(f\"GPU ì´ë¦„: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory // 1024**3} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jkciy6jhkbj",
      "metadata": {
        "id": "jkciy6jhkbj"
      },
      "source": [
        "### 3.2 MNIST ë°ì´í„°ì…‹ ë¡œë”©\n",
        "\n",
        "HuggingFace datasets ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ MNIST ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "isbz53sgt4o",
      "metadata": {
        "id": "isbz53sgt4o"
      },
      "outputs": [],
      "source": [
        "# MNIST ë°ì´í„°ì…‹ ë¡œë”©\n",
        "print(\"MNIST ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œ ì¤‘...\")\n",
        "mnist = load_dataset(\"mnist\")\n",
        "\n",
        "# ë°ì´í„°ì…‹ ì •ë³´ ì¶œë ¥\n",
        "print(\"\\n=== ë°ì´í„°ì…‹ ì •ë³´ ===\")\n",
        "print(f\"í›ˆë ¨ ë°ì´í„°: {len(mnist['train']):,}ê°œ\")\n",
        "print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(mnist['test']):,}ê°œ\")\n",
        "print(f\"í´ë˜ìŠ¤ ìˆ˜: {len(set(mnist['train']['label']))}ê°œ (0-9)\")\n",
        "print(f\"ì´ë¯¸ì§€ í¬ê¸°: {mnist['train'][0]['image'].size}\")\n",
        "\n",
        "# ìƒ˜í”Œ ì´ë¯¸ì§€ í™•ì¸\n",
        "sample_image = mnist['train'][0]['image']\n",
        "sample_label = mnist['train'][0]['label']\n",
        "print(f\"\\nì²« ë²ˆì§¸ ìƒ˜í”Œ: ë¼ë²¨ {sample_label}\")\n",
        "\n",
        "# í´ë˜ìŠ¤ë³„ ê°œìˆ˜ í™•ì¸\n",
        "from collections import Counter\n",
        "label_counts = Counter(mnist['train']['label'])\n",
        "print(\"\\ní´ë˜ìŠ¤ë³„ ë°ì´í„° ê°œìˆ˜:\")\n",
        "for i in range(10):\n",
        "    print(f\"ìˆ«ì {i}: {label_counts[i]:,}ê°œ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "frspnwc8rwb",
      "metadata": {
        "id": "frspnwc8rwb"
      },
      "source": [
        "### 3.3 ìƒ˜í”Œ ë°ì´í„° ì‹œê°í™”\n",
        "\n",
        "í•™ìŠµí•˜ê¸° ì „ì— ë°ì´í„°ê°€ ì–´ë–»ê²Œ ìƒê²¼ëŠ”ì§€ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uj8obxszxp",
      "metadata": {
        "id": "uj8obxszxp"
      },
      "outputs": [],
      "source": [
        "# ìƒ˜í”Œ ì´ë¯¸ì§€ë“¤ ì‹œê°í™”\n",
        "fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i in range(10):\n",
        "    # ê° ìˆ«ì(0-9)ì— ëŒ€í•´ ì²« ë²ˆì§¸ ìƒ˜í”Œ ì°¾ê¸°\n",
        "    for j, label in enumerate(mnist['train']['label']):\n",
        "        if label == i:\n",
        "            image = mnist['train'][j]['image']\n",
        "            axes[i].imshow(image, cmap='gray')\n",
        "            axes[i].set_title(f'Digit {i}')\n",
        "            axes[i].axis('off')\n",
        "            break\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('MNIST Dataset Samples (First image of each digit)', y=1.02)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vgb7ayrtxc",
      "metadata": {
        "id": "vgb7ayrtxc"
      },
      "source": [
        "### 3.4 ë°ì´í„° ì •ê·œí™” (Normalization)\n",
        "\n",
        "ì‹ ê²½ë§ì˜ í•™ìŠµì„ ì•ˆì •í™”í•˜ê¸° ìœ„í•´ í”½ì…€ ê°’ì„ ì •ê·œí™”í•©ë‹ˆë‹¤:\n",
        "1. í”½ì…€ ê°’ì„ 0-1 ë²”ìœ„ë¡œ ë³€í™˜ (ToTensor())\n",
        "2. í‰ê· ê³¼ í‘œì¤€í¸ì°¨ë¥¼ ì´ìš©í•´ ì •ê·œí™” (Normalize())\n",
        "\n",
        "ì •ê·œí™” ê³µì‹: `(í”½ì…€ê°’ - í‰ê· ) / í‘œì¤€í¸ì°¨`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f34pdhxwn5c",
      "metadata": {
        "id": "f34pdhxwn5c"
      },
      "outputs": [],
      "source": [
        "# ë°ì´í„°ì…‹ì˜ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ ê³„ì‚° (1000ê°œ ìƒ˜í”Œë¡œ ì¶”ì •)\n",
        "print(\"ë°ì´í„°ì…‹ì˜ í†µê³„ ì •ë³´ë¥¼ ê³„ì‚° ì¤‘...\")\n",
        "sample_data = torch.stack([\n",
        "    transforms.ToTensor()(mnist['train'][i]['image'])\n",
        "    for i in range(1000)\n",
        "])\n",
        "\n",
        "mean = sample_data.mean().item()\n",
        "std = sample_data.std().item()\n",
        "print(f\"í‰ê· (mean): {mean:.4f}\")\n",
        "print(f\"í‘œì¤€í¸ì°¨(std): {std:.4f}\")\n",
        "\n",
        "# Transform ì •ì˜\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),           # PIL Image -> Tensor, 0-255 -> 0-1\n",
        "    transforms.Normalize((mean,), (std,))  # ì •ê·œí™”\n",
        "])\n",
        "\n",
        "print(\"\\në³€í™˜ íŒŒì´í”„ë¼ì¸:\")\n",
        "print(\"1. ToTensor(): PIL Image -> PyTorch Tensor (0-255 -> 0-1)\")\n",
        "print(f\"2. Normalize(): (í”½ì…€ê°’ - {mean:.4f}) / {std:.4f}\")\n",
        "\n",
        "# ë³€í™˜ ì „í›„ ë¹„êµ\n",
        "original_pixel = mnist['train'][0]['image']\n",
        "transformed = transform(original_pixel)\n",
        "print(f\"\\në³€í™˜ ì˜ˆì‹œ:\")\n",
        "print(f\"ì›ë³¸ í”½ì…€ ë²”ìœ„: 0-255\")\n",
        "print(f\"ToTensor í›„: 0-1\")\n",
        "print(f\"ì •ê·œí™” í›„ ë²”ìœ„: ì•½ {transformed.min():.2f} ~ {transformed.max():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "h3ec7al6cl",
      "metadata": {
        "id": "h3ec7al6cl"
      },
      "source": [
        "### 3.5 DataLoader ìƒì„±\n",
        "\n",
        "DataLoaderëŠ” ë°ì´í„°ë¥¼ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë¶ˆëŸ¬ì˜¤ê³ , ì…”í”Œë§ ë“±ì˜ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6wfdp8efmyf",
      "metadata": {
        "id": "6wfdp8efmyf"
      },
      "outputs": [],
      "source": [
        "# ë°ì´í„° ë³€í™˜ í•¨ìˆ˜ ì •ì˜\n",
        "def transform_dataset(dataset):\n",
        "    \"\"\"ë°ì´í„°ì…‹ì— ë³€í™˜ì„ ì ìš©í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
        "    def transform_fn(batch):\n",
        "        # ì´ë¯¸ì§€ë¥¼ í…ì„œë¡œ ë³€í™˜í•˜ê³  28x28ì„ 784ë¡œ í‰íƒ„í™”\n",
        "        images = [transform(img).view(-1) for img in batch[\"image\"]]\n",
        "        return {\n",
        "            \"image\": torch.stack(images),\n",
        "            \"label\": torch.tensor(batch[\"label\"])\n",
        "        }\n",
        "    return dataset.with_transform(transform_fn)\n",
        "\n",
        "# í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì— ë³€í™˜ ì ìš©\n",
        "print(\"ë°ì´í„°ì…‹ ë³€í™˜ ì¤‘...\")\n",
        "train_dataset = transform_dataset(mnist[\"train\"])\n",
        "test_dataset = transform_dataset(mnist[\"test\"])\n",
        "\n",
        "# DataLoader ìƒì„±\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True  # í›ˆë ¨ ë°ì´í„°ëŠ” ì„ê¸°\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=test_batch_size,\n",
        "    shuffle=False  # í…ŒìŠ¤íŠ¸ ë°ì´í„°ëŠ” ìˆœì„œ ìœ ì§€\n",
        ")\n",
        "\n",
        "print(f\"í›ˆë ¨ DataLoader: {len(train_loader)}ê°œ ë°°ì¹˜\")\n",
        "print(f\"í…ŒìŠ¤íŠ¸ DataLoader: {len(test_loader)}ê°œ ë°°ì¹˜\")\n",
        "print(f\"ë°°ì¹˜ë‹¹ í›ˆë ¨ ìƒ˜í”Œ: {batch_size}ê°œ\")\n",
        "print(f\"ë°°ì¹˜ë‹¹ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ: {test_batch_size}ê°œ\")\n",
        "\n",
        "# ì²« ë²ˆì§¸ ë°°ì¹˜ í™•ì¸\n",
        "sample_batch = next(iter(train_loader))\n",
        "print(f\"\\nì²« ë²ˆì§¸ ë°°ì¹˜ shape:\")\n",
        "print(f\"ì´ë¯¸ì§€: {sample_batch['image'].shape}  # (batch_size, 784)\")\n",
        "print(f\"ë¼ë²¨: {sample_batch['label'].shape}    # (batch_size,)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6gulko7i5ql",
      "metadata": {
        "id": "6gulko7i5ql"
      },
      "source": [
        "## 4. ëª¨ë¸ í›ˆë ¨\n",
        "\n",
        "### 4.1 ëª¨ë¸, ì†ì‹¤í•¨ìˆ˜, ìµœì í™”ê¸° ì„¤ì •"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65a41rghsht",
      "metadata": {
        "id": "65a41rghsht"
      },
      "outputs": [],
      "source": [
        "# ëª¨ë¸ ì´ˆê¸°í™” (ì´ì „ì— ìƒì„±í•œ model ì¬ì‚¬ìš©í•˜ì§€ ì•Šê³  ìƒˆë¡œ ìƒì„±)\n",
        "model = MLP().to(device)  # ëª¨ë¸ì„ GPUë¡œ ì´ë™ (ìˆë‹¤ë©´)\n",
        "\n",
        "# ì†ì‹¤í•¨ìˆ˜: ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ë¥¼ ìœ„í•œ CrossEntropyLoss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# ìµœì í™”ê¸°: Adam (ì ì‘ì  í•™ìŠµë¥  ì•Œê³ ë¦¬ì¦˜)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "print(\"=== í›ˆë ¨ ì„¤ì • ===\")\n",
        "print(f\"ëª¨ë¸: {model.__class__.__name__}\")\n",
        "print(f\"ì†ì‹¤í•¨ìˆ˜: {criterion.__class__.__name__}\")\n",
        "print(f\"ìµœì í™”ê¸°: {optimizer.__class__.__name__}\")\n",
        "print(f\"ë””ë°”ì´ìŠ¤: {device}\")\n",
        "print(f\"ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in model.parameters()):,}ê°œ\")\n",
        "\n",
        "# í›ˆë ¨ ì„¤ì • ìš”ì•½\n",
        "print(f\"\\n=== í›ˆë ¨ ì •ë³´ ===\")\n",
        "print(f\"ì „ì²´ ì—í¬í¬: {nb_epochs}\")\n",
        "print(f\"ë°°ì¹˜ í¬ê¸°: {batch_size}\")\n",
        "print(f\"í•™ìŠµë¥ : {learning_rate}\")\n",
        "print(f\"ì—í¬í¬ë‹¹ ë°°ì¹˜ ìˆ˜: {len(train_loader)}\")\n",
        "print(f\"ì—í¬í¬ë‹¹ í›ˆë ¨ ìƒ˜í”Œ ìˆ˜: {len(train_loader) * batch_size:,}\")\n",
        "print(f\"ì „ì²´ í›ˆë ¨ ìŠ¤í…: {nb_epochs * len(train_loader):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "k9waf7yaxd",
      "metadata": {
        "id": "k9waf7yaxd"
      },
      "source": [
        "### 4.2 í›ˆë ¨ ë£¨í”„ ì‹¤í–‰\n",
        "\n",
        "ì‹ ê²½ë§ í›ˆë ¨ì˜ ê¸°ë³¸ ë‹¨ê³„:\n",
        "1. **Forward Pass**: ì…ë ¥ ë°ì´í„°ë¥¼ ëª¨ë¸ì— í†µê³¼ì‹œì¼œ ì˜ˆì¸¡ê°’ ê³„ì‚°\n",
        "2. **Loss ê³„ì‚°**: ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì˜ ì°¨ì´(ì˜¤ì°¨) ê³„ì‚°\n",
        "3. **Backward Pass**: ì—­ì „íŒŒë¥¼ í†µí•´ ê° íŒŒë¼ë¯¸í„°ì˜ ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°\n",
        "4. **Parameter Update**: ìµœì í™”ê¸°ë¥¼ ì‚¬ìš©í•´ íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3sp9z37zxiw",
      "metadata": {
        "id": "3sp9z37zxiw"
      },
      "outputs": [],
      "source": [
        "# í›ˆë ¨ ê³¼ì • ì¶”ì ì„ ìœ„í•œ ë¦¬ìŠ¤íŠ¸\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "test_accuracies = []\n",
        "\n",
        "print(\"=== í›ˆë ¨ ì‹œì‘ ===\\n\")\n",
        "\n",
        "for epoch in range(nb_epochs):\n",
        "    # í›ˆë ¨ ëª¨ë“œë¡œ ì„¤ì •\n",
        "    model.train()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "\n",
        "    for batch_idx, batch in enumerate(train_loader):\n",
        "        # ë°ì´í„°ë¥¼ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™\n",
        "        imgs = batch[\"image\"].to(device)\n",
        "        labels = batch[\"label\"].to(device)\n",
        "\n",
        "        # ê·¸ë˜ë””ì–¸íŠ¸ ì´ˆê¸°í™”\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(imgs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸\n",
        "        optimizer.step()\n",
        "\n",
        "        # í†µê³„ ì—…ë°ì´íŠ¸\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "        # 100 ë°°ì¹˜ë§ˆë‹¤ ì¤‘ê°„ ê²°ê³¼ ì¶œë ¥\n",
        "        if (batch_idx + 1) % 100 == 0:\n",
        "            current_loss = running_loss / (batch_idx + 1)\n",
        "            current_acc = 100 * correct_train / total_train\n",
        "            print(f\"Epoch [{epoch+1}/{nb_epochs}], Batch [{batch_idx+1}/{len(train_loader)}]\")\n",
        "            print(f\"  Loss: {current_loss:.4f}, Train Acc: {current_acc:.2f}%\")\n",
        "\n",
        "    # ì—í¬í¬ ì¢…ë£Œ í›„ í›ˆë ¨ í†µê³„\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_train_acc = 100 * correct_train / total_train\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_accuracies.append(epoch_train_acc)\n",
        "\n",
        "    print(f\"\\nEpoch [{epoch+1}/{nb_epochs}] í›ˆë ¨ ì™„ë£Œ:\")\n",
        "    print(f\"  í‰ê·  Loss: {epoch_loss:.4f}\")\n",
        "    print(f\"  í›ˆë ¨ ì •í™•ë„: {epoch_train_acc:.2f}%\")\n",
        "\n",
        "    # í…ŒìŠ¤íŠ¸ ì •í™•ë„ ê³„ì‚°\n",
        "    model.eval()  # í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •\n",
        "    correct_test = 0\n",
        "    total_test = 0\n",
        "\n",
        "    with torch.no_grad():  # ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° ë¹„í™œì„±í™”\n",
        "        for batch in test_loader:\n",
        "            imgs = batch[\"image\"].to(device)\n",
        "            labels = batch[\"label\"].to(device)\n",
        "\n",
        "            outputs = model(imgs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_test += labels.size(0)\n",
        "            correct_test += (predicted == labels).sum().item()\n",
        "\n",
        "    test_acc = 100 * correct_test / total_test\n",
        "    test_accuracies.append(test_acc)\n",
        "    print(f\"  í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_acc:.2f}%\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "print(f\"\\n=== í›ˆë ¨ ì™„ë£Œ ===\")\n",
        "print(f\"ìµœì¢… í›ˆë ¨ ì •í™•ë„: {train_accuracies[-1]:.2f}%\")\n",
        "print(f\"ìµœì¢… í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_accuracies[-1]:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pqku2b8psyn",
      "metadata": {
        "id": "pqku2b8psyn"
      },
      "source": [
        "## 5. ê²°ê³¼ ë¶„ì„ ë° ì‹œê°í™”\n",
        "\n",
        "### 5.1 í›ˆë ¨ ê³¼ì • ì‹œê°í™”\n",
        "\n",
        "Lossì™€ ì •í™•ë„ì˜ ë³€í™”ë¥¼ ê·¸ë˜í”„ë¡œ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "icbqk30iqt",
      "metadata": {
        "id": "icbqk30iqt"
      },
      "outputs": [],
      "source": [
        "# í›ˆë ¨ ê³¼ì • ì‹œê°í™”\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Loss ê·¸ë˜í”„\n",
        "epochs_range = range(1, nb_epochs + 1)\n",
        "ax1.plot(epochs_range, train_losses, 'b-', marker='o', linewidth=2, markersize=8)\n",
        "ax1.set_title('Training Loss', fontsize=14, fontweight='bold')\n",
        "ax1.set_xlabel('Epoch', fontsize=12)\n",
        "ax1.set_ylabel('Loss', fontsize=12)\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.set_xticks(epochs_range)\n",
        "\n",
        "# ì •í™•ë„ ê·¸ë˜í”„\n",
        "ax2.plot(epochs_range, train_accuracies, 'g-', marker='s', linewidth=2,\n",
        "         markersize=8, label='Train Accuracy')\n",
        "ax2.plot(epochs_range, test_accuracies, 'r-', marker='^', linewidth=2,\n",
        "         markersize=8, label='Test Accuracy')\n",
        "ax2.set_title('Accuracy Comparison', fontsize=14, fontweight='bold')\n",
        "ax2.set_xlabel('Epoch', fontsize=12)\n",
        "ax2.set_ylabel('Accuracy (%)', fontsize=12)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "ax2.legend(fontsize=11)\n",
        "ax2.set_xticks(epochs_range)\n",
        "ax2.set_ylim(80, 100)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ìµœì¢… ê²°ê³¼ ìš”ì•½\n",
        "print(\"=== ìµœì¢… ê²°ê³¼ ìš”ì•½ ===\")\n",
        "print(f\"ìµœì¢… í›ˆë ¨ Loss: {train_losses[-1]:.4f}\")\n",
        "print(f\"ìµœì¢… í›ˆë ¨ ì •í™•ë„: {train_accuracies[-1]:.2f}%\")\n",
        "print(f\"ìµœì¢… í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_accuracies[-1]:.2f}%\")\n",
        "print(f\"ê³¼ì í•© ì •ë„: {train_accuracies[-1] - test_accuracies[-1]:.2f}% (í›ˆë ¨-í…ŒìŠ¤íŠ¸ ì •í™•ë„ ì°¨ì´)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7u31xib5xoj",
      "metadata": {
        "id": "7u31xib5xoj"
      },
      "source": [
        "### 5.2 ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”\n",
        "\n",
        "ëª¨ë¸ì´ ì‹¤ì œë¡œ ì–´ë–»ê²Œ ì˜ˆì¸¡í•˜ëŠ”ì§€ ìƒ˜í”Œ ì´ë¯¸ì§€ë“¤ì„ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤. ì˜¬ë°”ë¥¸ ì˜ˆì¸¡ê³¼ í‹€ë¦° ì˜ˆì¸¡ì„ ëª¨ë‘ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iujp87752wh",
      "metadata": {
        "id": "iujp87752wh"
      },
      "outputs": [],
      "source": [
        "# ì˜ˆì¸¡ ìƒ˜í”Œ ìˆ˜ì§‘\n",
        "model.eval()\n",
        "correct_samples = []\n",
        "wrong_samples = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        imgs = batch[\"image\"].to(device)\n",
        "        labels = batch[\"label\"].to(device)\n",
        "        outputs = model(imgs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        # ì •í™•í•œ ì˜ˆì¸¡ê³¼ í‹€ë¦° ì˜ˆì¸¡ ë¶„ë¦¬\n",
        "        for i in range(len(imgs)):\n",
        "            if len(correct_samples) >= 7 and len(wrong_samples) >= 3:\n",
        "                break\n",
        "\n",
        "            sample = (imgs[i], labels[i], predicted[i], outputs[i])\n",
        "            if labels[i] == predicted[i] and len(correct_samples) < 7:\n",
        "                correct_samples.append(sample)\n",
        "            elif labels[i] != predicted[i] and len(wrong_samples) < 3:\n",
        "                wrong_samples.append(sample)\n",
        "\n",
        "        if len(correct_samples) >= 7 and len(wrong_samples) >= 3:\n",
        "            break\n",
        "\n",
        "# ì‹œê°í™”: 7ê°œ ë§ì¶˜ ê²ƒ + 3ê°œ í‹€ë¦° ê²ƒ\n",
        "display_samples = correct_samples + wrong_samples\n",
        "\n",
        "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, (img, true_label, pred_label, output) in enumerate(display_samples):\n",
        "    # 28x28ë¡œ reshape (ì •ê·œí™”ëœ ìƒíƒœ)\n",
        "    img_display = img.cpu().view(28, 28)\n",
        "\n",
        "    # ì •ê·œí™”ë¥¼ ì—­ë³€í™˜ (ì‹œê°í™”ë¥¼ ìœ„í•´)\n",
        "    img_display = img_display * std + mean\n",
        "    img_display = torch.clamp(img_display, 0, 1)\n",
        "\n",
        "    axes[i].imshow(img_display, cmap='gray')\n",
        "\n",
        "    # ìƒ‰ìƒ ì„¤ì •: ë§ìœ¼ë©´ ì´ˆë¡, í‹€ë¦¬ë©´ ë¹¨ê°•\n",
        "    color = 'green' if true_label == pred_label else 'red'\n",
        "    axes[i].set_title(f'True: {true_label.item()}, Pred: {pred_label.item()}', color=color, fontweight='bold')\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('Prediction Results (Green: Correct, Red: Wrong)', y=1.02, fontsize=16, fontweight='bold')\n",
        "plt.show()\n",
        "\n",
        "print(f\"ì˜¬ë°”ë¥¸ ì˜ˆì¸¡: {len([s for s in display_samples if s[1] == s[2]])}ê°œ\")\n",
        "print(f\"í‹€ë¦° ì˜ˆì¸¡: {len([s for s in display_samples if s[1] != s[2]])}ê°œ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bzow5k6y57j",
      "metadata": {
        "id": "bzow5k6y57j"
      },
      "source": [
        "### 5.3 ëª¨ë¸ì˜ í™•ì‹ ë„ ë¶„ì„\n",
        "\n",
        "í‹€ë¦¬ê²Œ ì˜ˆì¸¡í•œ ê²½ìš°, ëª¨ë¸ì´ ê° í´ë˜ìŠ¤ì— ëŒ€í•´ ì–¼ë§ˆë‚˜ í™•ì‹ í–ˆëŠ”ì§€ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7jz1pmdl16x",
      "metadata": {
        "id": "7jz1pmdl16x"
      },
      "outputs": [],
      "source": [
        "# í‹€ë¦° ì˜ˆì¸¡ì— ëŒ€í•œ ìƒì„¸ ë¶„ì„\n",
        "if wrong_samples:\n",
        "    wrong_img, wrong_true, wrong_pred, wrong_output = wrong_samples[0]\n",
        "\n",
        "    # ì†Œí”„íŠ¸ë§¥ìŠ¤ë¥¼ í†µí•´ í™•ë¥ ë¡œ ë³€í™˜\n",
        "    probabilities = torch.softmax(wrong_output, dim=0).cpu()\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "    # ì™¼ìª½: í‹€ë¦° ì˜ˆì¸¡ ì´ë¯¸ì§€\n",
        "    img_display = wrong_img.cpu().view(28, 28) * std + mean\n",
        "    img_display = torch.clamp(img_display, 0, 1)\n",
        "    ax1.imshow(img_display, cmap='gray')\n",
        "    ax1.set_title(f'Wrong Prediction Case\\\\nTrue: {wrong_true.item()}, Pred: {wrong_pred.item()}',\n",
        "                  color='red', fontsize=12, fontweight='bold')\n",
        "    ax1.axis('off')\n",
        "\n",
        "    # ì˜¤ë¥¸ìª½: í™•ë¥  ë¶„í¬\n",
        "    bars = ax2.bar(range(10), probabilities, alpha=0.7, color='lightblue', edgecolor='black')\n",
        "\n",
        "    # ì‹¤ì œ ë¼ë²¨ê³¼ ì˜ˆì¸¡ ë¼ë²¨ ê°•ì¡°\n",
        "    bars[wrong_true.item()].set_color('green')\n",
        "    bars[wrong_pred.item()].set_color('red')\n",
        "\n",
        "    ax2.set_xlabel('Digit Class', fontsize=11)\n",
        "    ax2.set_ylabel('Probability', fontsize=11)\n",
        "    ax2.set_title('Model Confidence by Class', fontsize=12, fontweight='bold')\n",
        "    ax2.set_xticks(range(10))\n",
        "    ax2.grid(axis='y', alpha=0.3)\n",
        "\n",
        "    # ë²”ë¡€ ì¶”ê°€\n",
        "    from matplotlib.lines import Line2D\n",
        "    legend_elements = [Line2D([0], [0], color='green', lw=4, label=f'True Label ({wrong_true.item()})'),\n",
        "                       Line2D([0], [0], color='red', lw=4, label=f'Predicted ({wrong_pred.item()})')]\n",
        "    ax2.legend(handles=legend_elements, loc='upper right')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # ìƒìœ„ 3ê°œ í™•ë¥  ì¶œë ¥\n",
        "    top3_probs, top3_indices = torch.topk(probabilities, 3)\n",
        "    print(\"\\\\n=== ëª¨ë¸ì˜ ìƒìœ„ 3ê°œ ì˜ˆì¸¡ ===\")\n",
        "    for i, (prob, idx) in enumerate(zip(top3_probs, top3_indices)):\n",
        "        print(f\"{i+1}ìœ„: ìˆ«ì {idx.item()} (í™•ë¥ : {prob.item()*100:.2f}%)\")\n",
        "\n",
        "    print(f\"\\\\nì‹¤ì œ ë¼ë²¨ {wrong_true.item()}ì˜ í™•ë¥ : {probabilities[wrong_true.item()]*100:.2f}%\")\n",
        "\n",
        "else:\n",
        "    print(\"í‹€ë¦° ì˜ˆì¸¡ ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤. ëª¨ë¸ì´ ëª¨ë“  í…ŒìŠ¤íŠ¸ ìƒ˜í”Œì„ ì •í™•íˆ ì˜ˆì¸¡í–ˆìŠµë‹ˆë‹¤!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fiwvxodjr8",
      "metadata": {
        "id": "2fiwvxodjr8"
      },
      "source": [
        "## 6. ê³¼ì œ ë° ì‹¤í—˜\n",
        "\n",
        "### ğŸ’¡ í•™ìŠµì„ ìœ„í•œ ì‹¤í—˜ ì œì•ˆ\n",
        "\n",
        "ì´ì œ ê¸°ë³¸ ëª¨ë¸ì„ ì´í•´í–ˆìœ¼ë‹ˆ, ë‹¤ìŒê³¼ ê°™ì€ ì‹¤í—˜ë“¤ì„ í•´ë³´ì„¸ìš”:\n",
        "\n",
        "#### ğŸ”§ **Try 1: í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹**\n",
        "- í•™ìŠµë¥ ì„ ë°”ê¿”ë³´ì„¸ìš” (`learning_rate = 1e-2`, `1e-4` ë“±)\n",
        "- ì€ë‹‰ì¸µ í¬ê¸°ë¥¼ ì¡°ì •í•´ë³´ì„¸ìš” (`hidden_size = 50`, `200` ë“±)\n",
        "- ì—í¬í¬ ìˆ˜ë¥¼ ëŠ˜ë ¤ë³´ì„¸ìš” (`nb_epochs = 5` ë˜ëŠ” `10`)\n",
        "\n",
        "#### ğŸ—ï¸ **Try 2: ëª¨ë¸ êµ¬ì¡° ê°œì„ **\n",
        "- ì€ë‹‰ì¸µì„ ë” ì¶”ê°€í•´ë³´ì„¸ìš” (3ì¸µ, 4ì¸µ ì‹ ê²½ë§)\n",
        "- ë‹¤ë¥¸ í™œì„±í™” í•¨ìˆ˜ë¥¼ ì‹œë„í•´ë³´ì„¸ìš” (`nn.Tanh()`, `nn.Sigmoid()`)\n",
        "- Dropoutì„ ì¶”ê°€í•´ì„œ ê³¼ì í•©ì„ ë°©ì§€í•´ë³´ì„¸ìš”\n",
        "\n",
        "#### ğŸ“ˆ **Try 3: ì„±ëŠ¥ ë¶„ì„**\n",
        "- Confusion Matrix ê·¸ë¦¬ê¸°\n",
        "- í´ë˜ìŠ¤ë³„ ì •í™•ë„ ë¶„ì„\n",
        "- ì˜ëª» ë¶„ë¥˜ëœ ì´ë¯¸ì§€ë“¤ì˜ íŒ¨í„´ ì°¾ê¸°\n",
        "\n",
        "### ğŸ“ **ì‹¤í—˜ ê²°ê³¼ ê¸°ë¡í•˜ê¸°**\n",
        "ê° ì‹¤í—˜ í›„ ë‹¤ìŒì„ ê¸°ë¡í•´ë³´ì„¸ìš”:\n",
        "- ìµœì¢… í…ŒìŠ¤íŠ¸ ì •í™•ë„\n",
        "- í›ˆë ¨ ì‹œê°„\n",
        "- ê´€ì°°ëœ íŒ¨í„´ì´ë‚˜ ì¸ì‚¬ì´íŠ¸"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py"
      ],
      "metadata": {
        "id": "R7Jsz_9wXoUh"
      },
      "id": "R7Jsz_9wXoUh",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}